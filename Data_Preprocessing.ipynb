{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f5153f-03ab-48ac-98de-73d11cf92803",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e031a4-8d59-4add-aa9a-25c928f8a694",
   "metadata": {},
   "source": [
    "**detect language**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1296e56b-76c6-4f27-9f66-9846fabb980e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              quote_text country_name  \\\n",
      "3694   A PORTER LA JOURNEE POUR TRAVAILLER , EN SOIRE...       France   \n",
      "4749   L'OFFRE NE CORRESPOND PAS A UN LOT DE TROIS ET...       France   \n",
      "5320                                        Tarif normal       France   \n",
      "5343   Points faibles    -NE SÉPARE PAS LES CILS    -...       France   \n",
      "10515        Packaging simple, list inkey plutôt propre.       France   \n",
      "\n",
      "      detected_language  \n",
      "3694                 en  \n",
      "4749                 en  \n",
      "5320                 en  \n",
      "5343                 en  \n",
      "10515                en  \n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0  # Ensure consistent results\n",
    "\n",
    "# Function to detect language\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'unknown'  # Handle cases where detection fails\n",
    "\n",
    "# Apply language detection\n",
    "df['detected_language'] = df['quote_text'].apply(detect_language)\n",
    "\n",
    "# Compare detected language with the country\n",
    "mismatched_language = df[(df['country_name'] == 'France') & (df['detected_language'] == 'en')]\n",
    "\n",
    "# Display mismatched examples\n",
    "print(mismatched_language[['quote_text', 'country_name', 'detected_language']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "08e0d402-0458-451d-849a-999e6110c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatched_language.to_csv('mismatched_language.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a863c0cf-5d8d-4627-bffb-de69f965cc21",
   "metadata": {},
   "source": [
    "**Train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "617392d0-312a-43f4-9f0e-4d246d9a8302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (88911, 10)\n",
      "Test set size: (22228, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load the data\n",
    "df = pd.read_parquet(\"dataset.parquet\")\n",
    "\n",
    "# do train-test split\n",
    "# since the distribution of languages, labels and topics are quite uniform\n",
    "# I just do simple train-test split for now\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Perform train-test split on the full DataFrame\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "\n",
    "# Check dataset sizes\n",
    "print(f\"Training set size: {df_train.shape}\")\n",
    "print(f\"Test set size: {df_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8259ffd9-a0f2-4228-a8f7-5cdd0925b01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in training set:\n",
      "label\n",
      "False    0.82532\n",
      "True     0.17468\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Label distribution in test set:\n",
      "label\n",
      "False    0.82531\n",
      "True     0.17469\n",
      "Name: proportion, dtype: float64\n",
      "Language distribution in training set:\n",
      "country_name\n",
      "United Kingdom    0.510567\n",
      "France            0.489433\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Language distribution in test set:\n",
      "country_name\n",
      "United Kingdom    0.513227\n",
      "France            0.486773\n",
      "Name: proportion, dtype: float64\n",
      "Topic distribution in training set:\n",
      "topic_id\n",
      "554.0    0.103215\n",
      "602.0    0.103001\n",
      "547.0    0.102765\n",
      "544.0    0.102401\n",
      "546.0    0.102144\n",
      "550.0    0.102101\n",
      "552.0    0.101930\n",
      "543.0    0.101544\n",
      "556.0    0.101330\n",
      "600.0    0.079569\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Topic distribution in test set:\n",
      "topic_id\n",
      "543.0    0.106677\n",
      "552.0    0.105152\n",
      "550.0    0.104474\n",
      "546.0    0.104304\n",
      "544.0    0.103288\n",
      "547.0    0.101847\n",
      "602.0    0.100915\n",
      "554.0    0.100068\n",
      "556.0    0.095238\n",
      "600.0    0.078038\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check the distribution on each data set\n",
    "print(\"Label distribution in training set:\")\n",
    "print(df_train['label'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nLabel distribution in test set:\")\n",
    "print(df_test['label'].value_counts(normalize=True))\n",
    "\n",
    "print(\"Language distribution in training set:\")\n",
    "print(df_train['country_name'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nLanguage distribution in test set:\")\n",
    "print(df_test['country_name'].value_counts(normalize=True))\n",
    "\n",
    "print(\"Topic distribution in training set:\")\n",
    "print(df_train['topic_id'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTopic distribution in test set:\")\n",
    "print(df_test['topic_id'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69d39e0-6bcf-47a8-a19d-e071bf1d501b",
   "metadata": {},
   "source": [
    "**clean the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01137541-52e5-4a30-a29f-d50b6fc34d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null and replace them with empty string\n",
    "# and also strip the text\n",
    "def clean_text(text):\n",
    "    text = str(text).strip() if pd.notna(text) else \"\"  # Handle NaN & strip spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b41ab14-ee18-4974-903b-ae6fabe8982e",
   "metadata": {},
   "source": [
    "**correct wrong spelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e8b28-5de8-4bb6-8106-1d8a4ba0fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d4d4400-8cbc-4d90-adde-d4af938931c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: France\n",
      "Original : Idéal pour créer une variété de coiffures sans tirer ni abîmer les cheveux\n",
      "Corrected: Idéal pour créer une variété de coiffures sans tirer ni abîmer les cheveux\n",
      "--------------------------------------------------\n",
      "Country: United Kingdom\n",
      "Original : but i found that this one was SO much better!!\n",
      "Corrected: but i found that this one was SO much better!!\n",
      "--------------------------------------------------\n",
      "Country: United Kingdom\n",
      "Original : It makes it ooze as soon as you uncap it and it makes a mess everywhere.\n",
      "Corrected: It makes it ooze as soon as you uncap it and it makes a mess everywhere.\n",
      "--------------------------------------------------\n",
      "Country: United Kingdom\n",
      "Original : I am in love with the beauty light wands and this one is no different it’s the perfect highlight shade and gives the most gorgeous glow and pillow talk hue to the skin!!\n",
      "Corrected: I am in love with the beauty light wands and this one is no different it’s the perfect highlight shade and gives the most gorgeous glow and pillow talk hue to the skin!!\n",
      "--------------------------------------------------\n",
      "Country: France\n",
      "Original : Je ne regrette pas du tout mon achat.\n",
      "Corrected: Je ne regrette pas du tout mon achat.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "# Load spell checkers for English and French\n",
    "spell_en = SpellChecker(language=\"en\")\n",
    "spell_fr = SpellChecker(language=\"fr\")\n",
    "\n",
    "# function to correct spelling\n",
    "def correct_tokens(tokens, spell):\n",
    "    \"\"\"\n",
    "    Corrects spelling of word tokens while keeping punctuation untouched.\n",
    "    \"\"\"\n",
    "    corrected_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.isalpha():  # Only check spelling for words\n",
    "            corrected_word = spell.correction(token)\n",
    "            corrected_tokens.append(corrected_word if corrected_word else token)  # Keep original if no correction\n",
    "        else:\n",
    "            corrected_tokens.append(token)  # Leave punctuation untouched\n",
    "    return corrected_tokens\n",
    "\n",
    "# function to assign spellcheck according to country\n",
    "def correct_spelling(text, country):\n",
    "    spell = spell_fr if country == 'France' else spell_en  # Choose correct spell checker\n",
    "    \n",
    "    tokens = text.split()  # Tokenize text\n",
    "    corrected_tokens = correct_tokens(tokens, spell)  # Apply spell checking\n",
    "    return \" \".join(corrected_tokens)  # Convert back to string\n",
    "\n",
    "# Test with sample rows\n",
    "sample_rows = df.sample(n=5, random_state=42)\n",
    "\n",
    "for _, row in sample_rows.iterrows():\n",
    "    original_text = row['quote_text']\n",
    "    country = row['country_name']\n",
    "    corrected_text = correct_spelling(original_text, country)\n",
    "\n",
    "    print(f\"Country: {country}\")\n",
    "    print(f\"Original : {original_text}\")\n",
    "    print(f\"Corrected: {corrected_text}\")\n",
    "    print(\"-\" * 50)  # Separator for readability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0273a09-2db7-470b-8a28-5a29e87fb58a",
   "metadata": {},
   "source": [
    "**replace emoji with the corresponding meaning in each language**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd83a5-ea11-4d73-993d-4a5179a82fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45164c48-37cb-4902-aa46-b95250c75df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: France\n",
      "Original : - Flacon à la contenance généreuse.\n",
      "With Emoji Text: - Flacon à la contenance généreuse.\n",
      "--------------------------------------------------\n",
      "Country: France\n",
      "Original : Je conseille ce produit pour les peaux très sèches et fragiles.\n",
      "With Emoji Text: Je conseille ce produit pour les peaux très sèches et fragiles.\n",
      "--------------------------------------------------\n",
      "Country: United Kingdom\n",
      "Original : I have shaken the moisturiser vigorously before use, and it makes a clicking sound, suggesting there might be a small sphere inside for mixing.\n",
      "With Emoji Text: I have shaken the moisturiser vigorously before use, and it makes a clicking sound, suggesting there might be a small sphere inside for mixing.\n",
      "--------------------------------------------------\n",
      "Country: United Kingdom\n",
      "Original : I have no complaints about this product.\n",
      "With Emoji Text: I have no complaints about this product.\n",
      "--------------------------------------------------\n",
      "Country: United Kingdom\n",
      "Original : Highly recommend this product.I also love the scent and the unique packaging.\n",
      "With Emoji Text: Highly recommend this product.I also love the scent and the unique packaging.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "# Function to replace emoji with text based on country\n",
    "def replace_emoji(text, country):\n",
    "    lang = \"fr\" if country == \"France\" else \"en\"  # Choose French or English\n",
    "    return emoji.demojize(text, language=lang).replace(\":\", \"\").replace(\"_\", \" \")  # Clean up output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67e702cc-07e7-4469-ba35-b3fd1a4a765f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               quote_text\n",
      "22      I really loved the packaging of this product i...\n",
      "108     The bottle is so pretty 😍 it's got a bit of a ...\n",
      "233     🥰❤️It has a unique aroma, I love it, and it is...\n",
      "445     but compared to my other selection of aftersha...\n",
      "1287    From the intriguing  packaging topped with a r...\n",
      "...                                                   ...\n",
      "110763                       ❤️ 5 starts for me for sure!\n",
      "110860  Brosse arrivée cassée, à la base de la brosse ...\n",
      "110903                    Et notre coiffeuse en a aussi 🤩\n",
      "110958                                Just as described 😎\n",
      "110987                     very fast delivery excellent 😊\n",
      "\n",
      "[1049 rows x 1 columns]\n",
      "Country: United Kingdom\n",
      "Original : I really loved the packaging of this product it's unique and beautiful 😍.\n",
      "With Emoji Text: I really loved the packaging of this product it's unique and beautiful smiling face with heart-eyes.\n",
      "--------------------------------------------------\n",
      "Country: United Kingdom\n",
      "Original : The bottle is so pretty 😍 it's got a bit of a curve to it so it stands out and the cap has some jelly material flowers that are so cute.\n",
      "With Emoji Text: The bottle is so pretty smiling face with heart-eyes it's got a bit of a curve to it so it stands out and the cap has some jelly material flowers that are so cute.\n",
      "--------------------------------------------------\n",
      "Country: United Kingdom\n",
      "Original : 🥰❤️It has a unique aroma, I love it, and it is very effective with its ingredients.\n",
      "With Emoji Text: smiling face with heartsred heartIt has a unique aroma, I love it, and it is very effective with its ingredients.\n",
      "--------------------------------------------------\n",
      "Country: United Kingdom\n",
      "Original : but compared to my other selection of aftershaves it's not strong enough to stand out for me, bought it about 2 weeks ago and used it twice, looks like one of my friends is getting a free full bottle of aftershave for free 😞\n",
      "With Emoji Text: but compared to my other selection of aftershaves it's not strong enough to stand out for me, bought it about 2 weeks ago and used it twice, looks like one of my friends is getting a free full bottle of aftershave for free disappointed face\n",
      "--------------------------------------------------\n",
      "Country: United Kingdom\n",
      "Original : From the intriguing  packaging topped with a raised 🧲 Magnet shape, to the unique Extender zig-zag bristle brush - it delivers a unique experience while deftly adding lift and realistic volume.\n",
      "With Emoji Text: From the intriguing  packaging topped with a raised magnet Magnet shape, to the unique Extender zig-zag bristle brush - it delivers a unique experience while deftly adding lift and realistic volume.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to check if a text contains emojis\n",
    "def contains_emoji(text):\n",
    "    text = str(text)  # Convert to string to avoid errors\n",
    "    return any(char in emoji.EMOJI_DATA for char in text)\n",
    "\n",
    "# Print rows containing emojis\n",
    "emoji_rows = df[df['quote_text'].apply(contains_emoji)]\n",
    "print(emoji_rows[['quote_text']])\n",
    "\n",
    "# try to see if we have replace them\n",
    "for _, row in emoji_rows.head().iterrows():\n",
    "    original_text = row['quote_text']\n",
    "    country = row['country_name']\n",
    "    replaced_text = replace_emoji(original_text, country)\n",
    "\n",
    "    print(f\"Country: {country}\")\n",
    "    print(f\"Original : {original_text}\")\n",
    "    print(f\"With Emoji Text: {replaced_text}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f48134e-7dfd-4f57-b2ca-db52eb066d5c",
   "metadata": {},
   "source": [
    "**lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e5256-d062-4801-bea7-12acd1367af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22c35504-23e2-4564-82d4-3c8fd9c5b9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl\n",
    "!pip install https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca1ea899-7f2b-4883-a490-7d7f13166d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: France\n",
      "Original : Idéal pour créer une variété de coiffures sans tirer ni abîmer les cheveux\n",
      "Lemmatized: idéal pour créer un variété de coiffure sans tirer ni abîmer le cheveu\n",
      "--------------------------------------------------\n",
      "Country: United Kingdom\n",
      "Original : but i found that this one was SO much better!!\n",
      "Lemmatized: but I find that this one be so much well ! !\n",
      "--------------------------------------------------\n",
      "Country: United Kingdom\n",
      "Original : It makes it ooze as soon as you uncap it and it makes a mess everywhere.\n",
      "Lemmatized: it make it ooze as soon as you uncap it and it make a mess everywhere .\n",
      "--------------------------------------------------\n",
      "Country: United Kingdom\n",
      "Original : I am in love with the beauty light wands and this one is no different it’s the perfect highlight shade and gives the most gorgeous glow and pillow talk hue to the skin!!\n",
      "Lemmatized: I be in love with the beauty light wand and this one be no different it ’ the perfect highlight shade and give the most gorgeous glow and pillow talk hue to the skin ! !\n",
      "--------------------------------------------------\n",
      "Country: France\n",
      "Original : Je ne regrette pas du tout mon achat.\n",
      "Lemmatized: je ne regretter pas de tout mon achat .\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English & French models\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "nlp_fr = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# Function to lemmatize text based on country\n",
    "def lemmatize_text(text, country):\n",
    "    nlp = nlp_fr if country == \"France\" else nlp_en  # Choose model\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])  # Get lemmatized words\n",
    "\n",
    "# Select a few random samples\n",
    "sample_rows = df.sample(n=5, random_state=42)\n",
    "\n",
    "for _, row in sample_rows.iterrows():\n",
    "    original_text = row['quote_text']\n",
    "    country = row['country_name']\n",
    "    lemmatized_text = lemmatize_text(original_text, country)\n",
    "\n",
    "    print(f\"Country: {country}\")\n",
    "    print(f\"Original : {original_text}\")\n",
    "    print(f\"Lemmatized: {lemmatized_text}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8422e597-1121-4d89-afed-7db8ad1e064f",
   "metadata": {},
   "source": [
    "**n-gram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "718a79e6-d4dd-49eb-b621-3a6958026e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "# Function to generate n-grams\n",
    "def generate_ngrams(text, n=2):\n",
    "    words = text.split()\n",
    "    ngrams = [\" \".join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "    return ngrams\n",
    "\n",
    "# Function to expand text with n-grams\n",
    "def add_ngrams(text, max_n=3):\n",
    "    words = text.split()\n",
    "    all_ngrams = words[:]  # Keep original unigrams\n",
    "    \n",
    "    for n in range(2, max_n+1):  # Generate bigrams, trigrams\n",
    "        all_ngrams.extend([\" \".join(words[i:i+n]) for i in range(len(words)-n+1)])\n",
    "\n",
    "    return \" \".join(all_ngrams)  # Join all n-grams into a single string\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "524a0dd5-7649-4e70-9432-a67a3efca240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: This perfume smells amazing and lasts long\n",
      "\n",
      " After N-Grams Processing: This perfume smells amazing and lasts long This perfume perfume smells smells amazing amazing and and lasts lasts long This perfume smells perfume smells amazing smells amazing and amazing and lasts and lasts long\n"
     ]
    }
   ],
   "source": [
    "test_text = \"This perfume smells amazing and lasts long\"\n",
    "\n",
    "print(\"Original Text:\", test_text)\n",
    "\n",
    "ngram_text = add_ngrams(test_text, max_n=3)\n",
    "print(\"\\n After N-Grams Processing:\", ngram_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c9cd6458-4afe-47db-8128-cd48c8ec39af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          processed_text\n",
      "67236  Idéal pour créer une variété de coiffures sans...\n",
      "76279  but i found that this one was SO much better!!...\n",
      "8525   It makes it ooze as soon as you uncap it and i...\n",
      "18197  I am in love with the beauty light wands and t...\n",
      "74427  Je ne regrette pas du tout mon achat. Je ne ne...\n"
     ]
    }
   ],
   "source": [
    "# Select a small random sample\n",
    "df_sample = df.sample(n=5, random_state=42).copy()\n",
    "\n",
    "# Apply pipeline on the sample (only process text, exclude embeddings for now)\n",
    "df_sample['processed_text'] = df_sample.apply(\n",
    "    lambda row: add_ngrams(row['quote_text'], 2), axis=1\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(df_sample[[ 'processed_text']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621ca5fd-f5b8-477f-aeb3-cf482e824954",
   "metadata": {},
   "source": [
    "**create a pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a5950e6-e8e2-423e-b0dd-2e72f1dc9f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_pipeline(text, country):\n",
    "    text = clean_text(text)\n",
    "    text = correct_spelling(text, country)\n",
    "    text = replace_emoji(text, country)\n",
    "    text = lemmatize_text(text, country)\n",
    "    text = add_ngrams(text, 2) # create bigram for now\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "df4b3677-511f-4f7b-aca2-dfd14d575207",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = []\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df_train.iterrows():\n",
    "    processed_text = process_text_pipeline(row['quote_text'], row['country_name'])\n",
    "    processed_texts.append(processed_text)\n",
    "\n",
    "# Assign lists back to the DataFrame\n",
    "df_train['processed_text_nsc'] = processed_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "40c87001-5220-4cef-8315-2a73e92349b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for df_test\n",
    "processed_texts = []\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    processed_text = process_text_pipeline(row['quote_text'], row['country_name'])\n",
    "    processed_texts.append(processed_text)\n",
    "\n",
    "df_test['processed_text_nsc'] = processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "41923a5f-c72a-484d-8aee-b1f9b545aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('df_train.csv', index=False)\n",
    "df_test.to_csv('df_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902128b9-5966-4ecf-8d80-955548eb6999",
   "metadata": {},
   "source": [
    "**create a version without spellcheck, as spellcheck might result in brandname etc being replaced? should not be, as if it return None we keep the original ones.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19e5f0c-6e8a-4e96-a6a9-164fac95b1de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# some fine tunning attempt on data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb6b23-8d24-4c22-89fd-269f7a3ee398",
   "metadata": {},
   "source": [
    "**out of vocabulary detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6257cce6-923c-4542-b96c-efb693dcf405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "import pandas as pd\n",
    "\n",
    "# Load spell checkers for English and French\n",
    "spell_en = SpellChecker(language=\"en\")\n",
    "spell_fr = SpellChecker(language=\"fr\")\n",
    "\n",
    "# Dictionary to collect unrecognized words\n",
    "unrecognized_words = []\n",
    "\n",
    "# Function to correct tokens and collect unrecognized words\n",
    "def correct_tokens(tokens, spell, original_text, country):\n",
    "    corrected_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.isalpha():  # Only check spelling for words\n",
    "            corrected_word = spell.correction(token)\n",
    "            if corrected_word is None:\n",
    "                # Collect unrecognized token with original quote and country\n",
    "                unrecognized_words.append({\n",
    "                    'Unrecognized_Word': token,\n",
    "                    'Original_Quote': original_text,\n",
    "                    'Country': country\n",
    "                })\n",
    "            corrected_tokens.append(corrected_word if corrected_word else token)  # Keep original if no correction\n",
    "        else:\n",
    "            corrected_tokens.append(token)  # Leave punctuation untouched\n",
    "    return corrected_tokens\n",
    "\n",
    "# Function to assign spellchecker based on country\n",
    "def correct_spelling(text, country):\n",
    "    spell = spell_fr if country == 'France' else spell_en  # Choose correct spell checker\n",
    "    tokens = text.split()  # Tokenize text\n",
    "    corrected_tokens = correct_tokens(tokens, spell, text, country)  # Apply spell checking and collect unrecognized words\n",
    "    return \" \".join(corrected_tokens)  # Convert back to string\n",
    "\n",
    "# Apply the correction function to the dataset (assuming 'df' is your DataFrame)\n",
    "_ = df.apply(lambda row: correct_spelling(row['quote_text'], row['country_name']), axis=1)\n",
    "\n",
    "# Convert unrecognized words into a DataFrame\n",
    "unrecognized_df = pd.DataFrame(unrecognized_words)\n",
    "\n",
    "# Display the first few unrecognized words\n",
    "print(unrecognized_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca14bff2-6e3e-4dcc-b662-6707933db771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect short quotes (1 or 2 words)\n",
    "def is_short_quote(text):\n",
    "    return 1 <= len(text.strip().split()) <= 2\n",
    "\n",
    "# Filter short quotes\n",
    "short_quotes = df[df['quote_text'].apply(is_short_quote)]\n",
    "\n",
    "# Display a few examples\n",
    "print(short_quotes[['quote_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c123abed-39a5-4b04-a20f-15183c036129",
   "metadata": {},
   "outputs": [],
   "source": [
    "unrecognized_df.to_csv('unrecognized_words.csv')\n",
    "short_quotes.to_csv('short_quotes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e47e63-5454-4920-b8cb-86d59c4e8a7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# try different embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "395b2227-6a54-4e07-9d8b-dfc6d021e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('df_train.csv')\n",
    "df_test = pd.read_csv('df_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f5d32a-5825-4685-a382-6f0a63ea3d35",
   "metadata": {},
   "source": [
    "**Do Kmeans, where topic id are given by majority vote of clusters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5510b166-9ac2-4a7f-a8a1-62ea71f5ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Prepare SBERT embeddings\n",
    "# Convert embeddings from lists to NumPy arrays\n",
    "df_train['word2vec_embedding'] = df_train['word2vec_embedding'].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else np.array(x))\n",
    "# Stack embeddings properly\n",
    "X = np.vstack(df_train['word2vec_embedding'].values)\n",
    "\n",
    "# Apply K-Means clustering\n",
    "k = 11  # Number of clusters, 10 topics add out of topic\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df_train['cluster'] = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f8185df-6133-42e8-9627-08a14bc2ab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          quote_text  cluster  topic_id\n",
      "0  J'ai d'abord cru à une lotion nettoyante, hydr...        0     552.0\n",
      "1  Je regrette juste que la recharge soit en plas...        0     554.0\n",
      "2  The packaging comes in a cute sturdy box, and ...        8     602.0\n",
      "3                                      Inadmissible.        6       NaN\n",
      "4  J'ai une dermathose séboréique, et le shampooi...        0       NaN\n",
      "                                          quote_text  cluster  topic_id  \\\n",
      "0  J'ai d'abord cru à une lotion nettoyante, hydr...        0     552.0   \n",
      "1  Je regrette juste que la recharge soit en plas...        0     554.0   \n",
      "2  The packaging comes in a cute sturdy box, and ...        8     602.0   \n",
      "3                                      Inadmissible.        6       NaN   \n",
      "4  J'ai une dermathose séboréique, et le shampooi...        0       NaN   \n",
      "\n",
      "   matched_topic_id  \n",
      "0             556.0  \n",
      "1             556.0  \n",
      "2             543.0  \n",
      "3             602.0  \n",
      "4             556.0  \n"
     ]
    }
   ],
   "source": [
    "# Check cluster assignments\n",
    "print(df_train[['quote_text', 'cluster', 'topic_id']].head())\n",
    "\n",
    "# Group by cluster and topic_id to see distribution\n",
    "cluster_topic_distribution = df_train.groupby(['cluster', 'topic_id']).size().reset_index(name='count')\n",
    "\n",
    "# Find the most common topic_id in each cluster\n",
    "cluster_to_topic = cluster_topic_distribution.sort_values('count', ascending=False).drop_duplicates('cluster')\n",
    "\n",
    "# Create a mapping from cluster to topic_id\n",
    "cluster_topic_mapping = dict(zip(cluster_to_topic['cluster'], cluster_to_topic['topic_id']))\n",
    "\n",
    "# Assign the matched topic_id back to the DataFrame\n",
    "df_train['matched_topic_id'] = df_train['cluster'].map(cluster_topic_mapping)\n",
    "\n",
    "# Check the mapping\n",
    "print(df_train[['quote_text', 'cluster', 'topic_id', 'matched_topic_id']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0366380-a9e0-4076-a902-be004ec6a92d",
   "metadata": {},
   "source": [
    "## sbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98abe335-b5fa-4178-9241-2141ff01e69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Sentence-BERT (SBERT)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load pre-trained SBERT model\n",
    "sbert_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "def get_sbert_embedding(text):\n",
    "    \"\"\"Generates sentence embedding using SBERT.\"\"\"\n",
    "    return sbert_model.encode(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb5f8e01-45e5-41e8-bf82-4e69f427f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_text (text, function):\n",
    "    return function(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd578e-532e-439f-b81a-a183da97520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_texts = []\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df_train.iterrows():\n",
    "    embedded_text = embedding_text(row['processed_text'],get_sbert_embedding)\n",
    "    embedded_texts.append(embedded_text)\n",
    "\n",
    "# Assign lists back to the DataFrame\n",
    "df_train['sbert_embedding'] = embedded_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52ee02f3-f425-470a-8074-16a1a9dc22fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_texts = []\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df_test.iterrows():\n",
    "    embedded_text = embedding_text(row['processed_text'],get_sbert_embedding)\n",
    "    embedded_texts.append(embedded_text)\n",
    "\n",
    "# Assign lists back to the DataFrame\n",
    "df_test['sbert_embedding'] = embedded_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afbce514-6c11-4762-bab2-60da5665e51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [0.31978327, 0.14027788, 0.08224525, 0.0696379...\n",
      "1        [0.093407236, 0.1766506, 0.046390157, 0.009621...\n",
      "2        [0.5187371, 0.14435184, -0.37031856, -0.191911...\n",
      "3        [0.14612241, 0.2545923, 0.3480164, 0.17786138,...\n",
      "4        [-0.029019503, 0.034514595, -0.14274204, -0.01...\n",
      "                               ...                        \n",
      "22223    [0.08779375, 0.022377515, 0.18306349, 0.192810...\n",
      "22224    [-0.11827949, 0.011398915, 0.10562416, 0.21336...\n",
      "22225    [0.07385143, 0.12553537, 0.030955251, -0.06214...\n",
      "22226    [0.058854192, 0.008282426, 0.09277359, -0.2619...\n",
      "22227    [0.1882922, 0.1822469, 0.2885761, 0.09011534, ...\n",
      "Name: sbert_embedding, Length: 22228, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_test['sbert_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba841cab-9635-46bf-a122-35c1e2d5c2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy (Topic Matching + Labels): 57.20%\n",
      "True Positive (TP): 2079\n",
      "True Negative (TN): 24629\n",
      "False Positive (FP): 6529\n",
      "False Negative (FN): 13452\n"
     ]
    }
   ],
   "source": [
    "# Filter labeled data (with known topic_id)\n",
    "labeled_data = df_train[df_train['topic_id'].notnull()]\n",
    "\n",
    "# Define the conditions\n",
    "true_positive = (labeled_data['label'] == True) & (labeled_data['matched_topic_id'] == labeled_data['topic_id'])\n",
    "true_negative = (labeled_data['label'] == False) & (labeled_data['matched_topic_id'] != labeled_data['topic_id'])\n",
    "false_positive = (labeled_data['label'] == False) & (labeled_data['matched_topic_id'] == labeled_data['topic_id'])\n",
    "false_negative = (labeled_data['label'] == True) & (labeled_data['matched_topic_id'] != labeled_data['topic_id'])\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = true_positive | true_negative\n",
    "combined_accuracy = correct_predictions.mean()\n",
    "\n",
    "# Display accuracy\n",
    "print(f\"Overall Accuracy (Topic Matching + Labels): {combined_accuracy:.2%}\")\n",
    "\n",
    "# Optional: Display counts for TP, TN, FP, FN\n",
    "print(f\"True Positive (TP): {true_positive.sum()}\")\n",
    "print(f\"True Negative (TN): {true_negative.sum()}\")\n",
    "print(f\"False Positive (FP): {false_positive.sum()}\")\n",
    "print(f\"False Negative (FN): {false_negative.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f7e3be3-ff04-4733-a701-21e3fd361f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test['sbert_embedding'] = df_test['sbert_embedding'].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else np.array(x))\n",
    "\n",
    "# Stack embeddings into a NumPy array\n",
    "X = np.vstack(df_test['sbert_embedding'].values).astype(np.float64)\n",
    "\n",
    "# Apply K-Means prediction\n",
    "df_test['cluster'] = kmeans.predict(X)\n",
    "\n",
    "df_test['matched_topic_id'] = df_test['cluster'].map(cluster_topic_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3be8fc1a-1e9e-4541-8f71-0550aac9796b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy (Topic Matching + Labels): 77.26%\n",
      "True Positive (TP): 283\n",
      "True Negative (TN): 8777\n",
      "False Positive (FP): 897\n",
      "False Negative (FN): 1769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8746/358751175.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  labeled_data = df_test[df_train['topic_id'].notnull()]\n"
     ]
    }
   ],
   "source": [
    "labeled_data = df_test[df_train['topic_id'].notnull()]\n",
    "\n",
    "# Define the conditions\n",
    "true_positive = (labeled_data['label'] == True) & (labeled_data['matched_topic_id'] == labeled_data['topic_id'])\n",
    "true_negative = (labeled_data['label'] == False) & (labeled_data['matched_topic_id'] != labeled_data['topic_id'])\n",
    "false_positive = (labeled_data['label'] == False) & (labeled_data['matched_topic_id'] == labeled_data['topic_id'])\n",
    "false_negative = (labeled_data['label'] == True) & (labeled_data['matched_topic_id'] != labeled_data['topic_id'])\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = true_positive | true_negative\n",
    "combined_accuracy = correct_predictions.mean()\n",
    "\n",
    "# Display accuracy\n",
    "print(f\"Overall Accuracy (Topic Matching + Labels): {combined_accuracy:.2%}\")\n",
    "\n",
    "# Optional: Display counts for TP, TN, FP, FN\n",
    "print(f\"True Positive (TP): {true_positive.sum()}\")\n",
    "print(f\"True Negative (TN): {true_negative.sum()}\")\n",
    "print(f\"False Positive (FP): {false_positive.sum()}\")\n",
    "print(f\"False Negative (FN): {false_negative.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10c9b5db-2936-471d-acc5-dcb35233a631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " TP: 544, FP: 1669, FN: 3339, TN: 16676\n",
      "Accuracy: 77.47%\n",
      "Precision: 24.58%\n",
      "Recall (Correct Topic Retrieval Rate): 14.01%\n",
      "F1-Score: 17.85%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "# Convert matching results into binary form\n",
    "y_true = (df_test['label'] == True)  # True labels\n",
    "y_pred = (df_test['matched_topic_id'] == df_test['topic_id'])  # Model's predictions\n",
    "\n",
    "# Compute confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred) # TP/(TP+FP)\n",
    "recall = recall_score(y_true, y_pred)  # This is TP / (TP + FN)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Confusion Matrix:\\n TP: {tp}, FP: {fp}, FN: {fn}, TN: {tn}\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"Recall (Correct Topic Retrieval Rate): {recall:.2%}\")\n",
    "print(f\"F1-Score: {f1:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bab00b1-e5d4-4149-8b9f-8fc73b6eea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('df_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421d409b-07c2-4ab4-86bc-79cb7c8ff86c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd533fa-a482-46f2-ad7b-a654b979437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT (Base Model + CLS Token)\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "def get_bert_cls_embedding(text):\n",
    "    \"\"\"Generates sentence embedding using the CLS token from BERT.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze().numpy()  # CLS token embedding\n",
    "\n",
    "# Example usage\n",
    "text = \"This is a sample text.\"\n",
    "bert_cls_embedding = get_bert_cls_embedding(text)\n",
    "\n",
    "# Display the shape of the embedding\n",
    "print(\"BERT CLS Token Embedding Shape:\", bert_cls_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af962d6c-9d91-4d96-b31b-91767a1aeef3",
   "metadata": {},
   "source": [
    "## word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a02bf3fd-2900-4983-a2cf-5b1a452bf805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smart_open in /opt/conda/lib/python3.12/site-packages (7.1.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.12/site-packages (from smart_open) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install smart_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d87dfea-afa4-48a9-ae86-95b9cb75e18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a172330-0a29-4a2c-9d80-fb6c198fe417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in 'processed_text': 2\n"
     ]
    }
   ],
   "source": [
    "# Count NaN values in the processed_text column\n",
    "nan_count = df_train['processed_text'].isna().sum()\n",
    "\n",
    "print(f\"Number of NaN values in 'processed_text': {nan_count}\")\n",
    "\n",
    "# Replace NaN with an empty string\n",
    "df_train['processed_text'] = df_train['processed_text'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8ae894f-8c3a-40f9-8b58-fe03f78c7aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      processed_text  \\\n",
      "0  je avoir de abord croire à un lotion nettoyant...   \n",
      "1  je regretter juste que le recharge être en pla...   \n",
      "2  the packaging come in a cute sturdy box , and ...   \n",
      "3                      Inadmissible . Inadmissible .   \n",
      "4  je avoir un dermatose séboréiqu , et le shampo...   \n",
      "\n",
      "                                      tokenized_text  \n",
      "0  [je, avoir, de, abord, croire, à, un, lotion, ...  \n",
      "1  [je, regretter, juste, que, le, recharge, être...  \n",
      "2  [the, packaging, come, in, a, cute, sturdy, bo...  \n",
      "3                 [Inadmissible, ., Inadmissible, .]  \n",
      "4  [je, avoir, un, dermatose, séboréiqu, ,, et, l...  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load language models\n",
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "nlp_fr = spacy.load('fr_core_news_sm')\n",
    "\n",
    "# Tokenization function\n",
    "def spacy_tokenize(text, lang='en'):\n",
    "    nlp = nlp_fr if lang == 'fr' else nlp_en\n",
    "    return [token.text for token in nlp(text)]\n",
    "\n",
    "# Apply tokenization based on country_name\n",
    "df_train['tokenized_text'] = df_train.apply(\n",
    "    lambda row: spacy_tokenize(row['processed_text'], 'fr' if row['country_name'] == 'France' else 'en'),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Check tokenized output\n",
    "print(df_train[['processed_text', 'tokenized_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e49ede93-ddb2-4e60-99a4-2835686bec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      processed_text  \\\n",
      "0  je avoir de abord croire à un lotion nettoyant...   \n",
      "1  je regretter juste que le recharge être en pla...   \n",
      "2  the packaging come in a cute sturdy box , and ...   \n",
      "3                      Inadmissible . Inadmissible .   \n",
      "4  je avoir un dermatose séboréiqu , et le shampo...   \n",
      "\n",
      "                                  word2vec_embedding  \n",
      "0  [0.8978163, 0.121954896, 0.30679128, 1.1866511...  \n",
      "1  [1.5041182, 0.74539626, 0.66749245, 0.8765296,...  \n",
      "2  [-1.3043804, -1.1020962, -0.007926899, -0.8447...  \n",
      "3  [0.5184143, -0.92831206, -0.88179547, -0.12716...  \n",
      "4  [0.76718295, -0.15469556, 0.87029487, 1.191067...  \n"
     ]
    }
   ],
   "source": [
    "# Word2Vec Embedding\n",
    "import smart_open\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize the processed text\n",
    "#df_train['tokenized_text'] = df_train['processed_text'].apply(word_tokenize)\n",
    "\n",
    "# Train the Word2Vec model\n",
    "# from scratch\n",
    "w2v_model = Word2Vec(sentences=df_train['tokenized_text'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get the average Word2Vec embedding for each quote\n",
    "def get_word2vec_embedding(tokens, model):\n",
    "    # Filter out tokens not in the model's vocabulary\n",
    "    valid_tokens = [token for token in tokens if token in model.wv]\n",
    "    \n",
    "    if valid_tokens:\n",
    "        return np.mean(model.wv[valid_tokens], axis=0)\n",
    "    else:\n",
    "        # Return a zero vector if no valid tokens are found\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Apply the function to get embeddings\n",
    "df_train['word2vec_embedding'] = df_train['tokenized_text'].apply(lambda tokens: get_word2vec_embedding(tokens, w2v_model))\n",
    "\n",
    "# Display some embeddings\n",
    "print(df_train[['processed_text', 'word2vec_embedding']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ac1c83c-8ed2-404d-877e-848a707095b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy (Topic Matching + Labels): 59.53%\n",
      "True Positive (TP): 2332\n",
      "True Negative (TN): 25464\n",
      "False Positive (FP): 5694\n",
      "False Negative (FN): 13199\n"
     ]
    }
   ],
   "source": [
    "# Filter labeled data (with known topic_id)\n",
    "labeled_data = df_train[df_train['topic_id'].notnull()]\n",
    "\n",
    "# Define the conditions\n",
    "true_positive = (labeled_data['label'] == True) & (labeled_data['matched_topic_id'] == labeled_data['topic_id'])\n",
    "true_negative = (labeled_data['label'] == False) & (labeled_data['matched_topic_id'] != labeled_data['topic_id'])\n",
    "false_positive = (labeled_data['label'] == False) & (labeled_data['matched_topic_id'] == labeled_data['topic_id'])\n",
    "false_negative = (labeled_data['label'] == True) & (labeled_data['matched_topic_id'] != labeled_data['topic_id'])\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = true_positive | true_negative\n",
    "combined_accuracy = correct_predictions.mean()\n",
    "\n",
    "# Display accuracy\n",
    "print(f\"Overall Accuracy (Topic Matching + Labels): {combined_accuracy:.2%}\")\n",
    "\n",
    "# Optional: Display counts for TP, TN, FP, FN\n",
    "print(f\"True Positive (TP): {true_positive.sum()}\")\n",
    "print(f\"True Negative (TN): {true_negative.sum()}\")\n",
    "print(f\"False Positive (FP): {false_positive.sum()}\")\n",
    "print(f\"False Negative (FN): {false_negative.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f62fe34-eacb-4f04-a6ed-1c63a9d704bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['tokenized_text'] = df_test.apply(\n",
    "    lambda row: spacy_tokenize(row['processed_text'], 'fr' if row['country_name'] == 'France' else 'en'),\n",
    "    axis=1\n",
    ")\n",
    "df_test['word2vec_embedding'] = df_test['tokenized_text'].apply(lambda tokens: get_word2vec_embedding(tokens, w2v_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7add5f98-7ecb-4a61-b9b6-4ba46f82d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for df_test\n",
    "X = np.vstack(df_test['word2vec_embedding'].values)\n",
    "df_test['cluster'] = kmeans.predict(X)\n",
    "# map to the topic id\n",
    "df_test['matched_topic_id'] = df_test['cluster'].map(cluster_topic_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a9d31f4b-56e7-4e9a-8f20-64c83ca055ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy (Topic Matching + Labels): 59.96%\n",
      "True Positive (TP): 608\n",
      "True Negative (TN): 6469\n",
      "False Positive (FP): 1450\n",
      "False Negative (FN): 3275\n"
     ]
    }
   ],
   "source": [
    "# Filter labeled data (with known topic_id)\n",
    "labeled_data = df_test[df_test['topic_id'].notnull()]\n",
    "\n",
    "# Define the conditions\n",
    "true_positive = (labeled_data['label'] == True) & (labeled_data['matched_topic_id'] == labeled_data['topic_id'])\n",
    "true_negative = (labeled_data['label'] == False) & (labeled_data['matched_topic_id'] != labeled_data['topic_id'])\n",
    "false_positive = (labeled_data['label'] == False) & (labeled_data['matched_topic_id'] == labeled_data['topic_id'])\n",
    "false_negative = (labeled_data['label'] == True) & (labeled_data['matched_topic_id'] != labeled_data['topic_id'])\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = true_positive | true_negative\n",
    "combined_accuracy = correct_predictions.mean()\n",
    "\n",
    "# Display accuracy\n",
    "print(f\"Overall Accuracy (Topic Matching + Labels): {combined_accuracy:.2%}\")\n",
    "\n",
    "# Optional: Display counts for TP, TN, FP, FN\n",
    "print(f\"True Positive (TP): {true_positive.sum()}\")\n",
    "print(f\"True Negative (TN): {true_negative.sum()}\")\n",
    "print(f\"False Positive (FP): {false_positive.sum()}\")\n",
    "print(f\"False Negative (FN): {false_negative.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "877b867e-940b-4f39-a718-a82312a9e512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " TP: 608, FP: 1450, FN: 3275, TN: 16895\n",
      "Accuracy: 78.74%\n",
      "Precision: 29.54%\n",
      "Recall (Correct Topic Retrieval Rate): 15.66%\n",
      "F1-Score: 20.47%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "# Convert matching results into binary form\n",
    "y_true = (df_test['label'] == True)  # True labels\n",
    "y_pred = (df_test['matched_topic_id'] == df_test['topic_id'])  # Model's predictions\n",
    "\n",
    "# Compute confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred) # TP/(TP+FP)\n",
    "recall = recall_score(y_true, y_pred)  # This is TP / (TP + FN)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Confusion Matrix:\\n TP: {tp}, FP: {fp}, FN: {fn}, TN: {tn}\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"Recall (Correct Topic Retrieval Rate): {recall:.2%}\")\n",
    "print(f\"F1-Score: {f1:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9096a9c-7812-41db-bd24-d6edfb7a19b3",
   "metadata": {},
   "source": [
    "**try different embedding, know the key structure and intuition behind!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26dc1239-568b-402d-a929-8ee3399cf3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading .npy file: cannot reshape array of size 696254432 into shape (3000000,300)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    data = np.load('word2vec-google-news-300.model.vectors.npy', allow_pickle=True)\n",
    "    print(data.shape)  # Check the shape of the array\n",
    "except Exception as e:\n",
    "    print(f\"Error loading .npy file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff1fee5-f83c-496f-88ab-53a279b057b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (e.g., Google News vectors)\n",
    "import gensim\n",
    "\n",
    "# Load pre-trained Word2Vec model.\n",
    "model = gensim.models.Word2Vec.load(\"word2vec-google-news-300.model\")\n",
    "#from gensim.models import KeyedVectors\n",
    "#w2v_model_pretrained = KeyedVectors.load_word2vec_format('word2vec-google-news-300.bin', binary = True)\n",
    "\n",
    "# Fine-tune on your data\n",
    "w2v_model_pretrained.build_vocab(df_train['tokenized_text'], update=True)\n",
    "w2v_model_pretrained.train(df_train['tokenized_text'], total_examples=w2v_model_pretrained.corpus_count, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c21f46-50ad-4084-9aa2-b6fefb6cb788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
