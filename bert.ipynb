{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da02e0e-eb17-435d-8c0e-188701eafd61",
   "metadata": {},
   "source": [
    "# sbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39b08b33-95a0-44f8-a0bb-ae160a617c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_preprocessing' from '/home/onyxia/work/data_preprocessing.py'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import data_preprocessing  # Make sure it's already imported\n",
    "importlib.reload(data_preprocessing)  # Force reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "949351ed-75d2-4b08-9fa5-79eddc485d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import data_preprocessing\n",
    "from data_preprocessing import clean_text, correct_spelling, replace_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9a85736-092e-4a59-90d0-159e55dfd85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"dataset.parquet\")\n",
    "label_df = df[df['label'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ee6d359-f689-408e-8f72-12951a62cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train_label, df_test_label = train_test_split(label_df, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f377149f-b6b8-4a9f-a1c1-803a68ea3d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing, skip lemmanization for bert and sbert\n",
    "def process_text_pipeline(text, country):\n",
    "    text = clean_text(text)\n",
    "    text = correct_spelling(text, country)\n",
    "    text = replace_emoji(text, country)\n",
    "    return text\n",
    "\n",
    "# process for df_train\n",
    "processed_texts = []\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df_train_label.iterrows():\n",
    "    processed_text = process_text_pipeline(row['quote_text'], row['country_name'])\n",
    "    processed_texts.append(processed_text)\n",
    "\n",
    "# Assign lists back to the DataFrame\n",
    "df_train_label['processed_text_nsc'] = processed_texts\n",
    "\n",
    "# Repeat for df_test\n",
    "processed_texts = []\n",
    "\n",
    "for index, row in df_test_label.iterrows():\n",
    "    processed_text = process_text_pipeline(row['quote_text'], row['country_name'])\n",
    "    processed_texts.append(processed_text)\n",
    "\n",
    "df_test_label['processed_text_nsc'] = processed_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da657b5-0fd1-44a9-9843-715a4ccdf7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence-BERT (SBERT)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# Load pre-trained SBERT model\n",
    "sbert_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "def get_sbert_embedding(text):\n",
    "    \"\"\"Generates sentence embedding using SBERT.\"\"\"\n",
    "    return sbert_model.encode(text)\n",
    "\n",
    "# get embedding for training set\n",
    "embedded_texts = []\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df_train_label.iterrows():\n",
    "    embedded_text = get_sbert_embedding(row['processed_text_nsc'])\n",
    "    embedded_texts.append(embedded_text)\n",
    "\n",
    "# Assign lists back to the DataFrame\n",
    "df_train_label['sbert_embedding'] = embedded_texts\n",
    "\n",
    "# for test set\n",
    "embedded_texts = []\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df_test_label.iterrows():\n",
    "    embedded_text = get_sbert_embedding(row['processed_text_nsc'])\n",
    "    embedded_texts.append(embedded_text)\n",
    "\n",
    "# Assign lists back to the DataFrame\n",
    "df_test_label['sbert_embedding'] = embedded_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d23d7e1-4270-420d-8375-3228741fea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign lists back to the DataFrame\n",
    "df_train_label['sbert_embedding'] = embedded_texts\n",
    "\n",
    "# for test set\n",
    "embedded_texts = []\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df_test_label.iterrows():\n",
    "    embedded_text = get_sbert_embedding(row['processed_text_nsc'])\n",
    "    embedded_texts.append(embedded_text)\n",
    "\n",
    "# Assign lists back to the DataFrame\n",
    "df_test_label['sbert_embedding'] = embedded_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2210d1af-b061-4130-9b6b-479ea4baef36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a5f125b1-ccf7-433e-9965-c4f528e0df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Prepare SBERT embeddings\n",
    "# Convert embeddings from lists to NumPy arrays\n",
    "df_train_label['sbert_embedding'] = df_train_label['sbert_embedding'].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else np.array(x))\n",
    "# Stack embeddings properly\n",
    "X = np.vstack(df_train_label['sbert_embedding'].values)\n",
    "\n",
    "# Apply K-Means clustering\n",
    "k = 11  # Number of clusters, 10 topics add out of topic\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df_train_label['cluster'] = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3bbae64-fe00-4b30-8c7a-d3061766fd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              quote_text  cluster  topic_id  \\\n",
      "38030  The face cream was easy to pump out and I didn...        5     550.0   \n",
      "50679  Très bonne idée la recharge, pour partir en vo...        2     556.0   \n",
      "35584  J’utilise ce produit depuis 2 mois maintenant ...        5     546.0   \n",
      "44679  This set of 3 masks comes in a fully recycled ...       10     602.0   \n",
      "33645  Points forts    Format automatique pratique, s...        2     546.0   \n",
      "\n",
      "       matched_topic_id  \n",
      "38030             550.0  \n",
      "50679             546.0  \n",
      "35584             550.0  \n",
      "44679             602.0  \n",
      "33645             546.0  \n"
     ]
    }
   ],
   "source": [
    "# Group by cluster and topic_id to see distribution\n",
    "cluster_topic_distribution = df_train_label.groupby(['cluster', 'topic_id']).size().reset_index(name='count')\n",
    "\n",
    "# Find the most common topic_id in each cluster\n",
    "cluster_to_topic = cluster_topic_distribution.sort_values('count', ascending=False).drop_duplicates('cluster')\n",
    "\n",
    "# Create a mapping from cluster to topic_id\n",
    "cluster_topic_mapping = dict(zip(cluster_to_topic['cluster'], cluster_to_topic['topic_id']))\n",
    "\n",
    "# Assign the matched topic_id back to the DataFrame\n",
    "df_train_label['matched_topic_id'] = df_train_label['cluster'].map(cluster_topic_mapping)\n",
    "\n",
    "# Check the mapping\n",
    "print(df_train_label[['quote_text', 'cluster', 'topic_id', 'matched_topic_id']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "782f532a-687e-4b4b-8328-95305f1632e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for df_test\n",
    "df_test_label['sbert_embedding'] = df_test_label['sbert_embedding'].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else np.array(x))\n",
    "X = np.vstack(df_test_label['sbert_embedding'].values)#.astype(np.float64)\n",
    "df_test_label['cluster'] = kmeans.predict(X)\n",
    "# map to the topic id\n",
    "df_test_label['matched_topic_id'] = df_test_label['cluster'].map(cluster_topic_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "96c1a94b-5d33-4129-a70e-f51bba2b10d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.4351297405189621\n",
      "test accuracy: 0.4421838784445017\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = np.sum(df_train_label['matched_topic_id'] == df_train_label['topic_id'])/len(df_train_label)\n",
    "test_accuracy = np.sum(df_test_label['matched_topic_id'] == df_test_label['topic_id'])/len(df_test_label)\n",
    "print('train accuracy:', train_accuracy)\n",
    "print('test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f06a4-c1bf-49f0-8492-989bcbd693e6",
   "metadata": {},
   "source": [
    "# bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5e2fad-1c21-41a2-bf0e-a2cfcf9e15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0764f3d-a052-4abc-a71a-0465e33fd228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load BERT base model and tokenizer\n",
    "# for now try the most basic pretrained\n",
    "bert_model_name = \"bert-base-uncased\"  \n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4317299-0fa2-4181-83fb-029c9ffb0a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_word_embeddings(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Extracts word embeddings from BERT for a given text.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): Input text\n",
    "    - model (transformers.BertModel): Pretrained BERT model\n",
    "    - tokenizer (transformers.BertTokenizer): BERT tokenizer\n",
    "\n",
    "    Returns:\n",
    "    - word_embeddings (numpy array): Word-level embeddings\n",
    "    \"\"\"\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "\n",
    "    # Get last hidden states (shape: [batch_size, num_tokens, embedding_size])\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "    return last_hidden_state.squeeze(0).numpy()  # Convert tensor to numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a1799-500c-47a7-85c4-c60078214577",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_texts = []\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df_train_label.iterrows():\n",
    "    embedded_text = get_bert_word_embeddings(row['processed_text_nsc'], bert_model, tokenizer)\n",
    "    embedded_texts.append(embedded_text)\n",
    "\n",
    "# Assign lists back to the DataFrame\n",
    "df_train_label['bert_embedding'] = embedded_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f1ece04-0900-47a0-ab8e-8d07d4e849ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test set\n",
    "embedded_texts = []\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df_test_label.iterrows():\n",
    "    embedded_text = get_bert_word_embeddings(row['processed_text_nsc'], bert_model, tokenizer)\n",
    "    embedded_texts.append(embedded_text)\n",
    "\n",
    "# Assign lists back to the DataFrame\n",
    "df_test_label['bert_embedding'] = embedded_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac21b99b-b077-44e3-9d85-d27617c08f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_pooling(embedding):\n",
    "    \"\"\" Convert variable-length BERT word embeddings to a fixed-size 768D vector (sentence embedding). \"\"\"\n",
    "    return np.mean(embedding, axis=0) if embedding.shape[0] > 1 else embedding.squeeze()\n",
    "\n",
    "# Apply mean pooling to all embeddings\n",
    "df_train_label[\"bert_embedding\"] = df_train_label[\"bert_embedding\"].apply(mean_pooling)\n",
    "df_test_label[\"bert_embedding\"] = df_test_label[\"bert_embedding\"].apply(mean_pooling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93d6593e-df03-4260-99e7-0fd5df7afd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack(df_train_label[\"bert_embedding\"].values)  # Now shape: (num_samples, 768)\n",
    "X_test = np.vstack(df_test_label[\"bert_embedding\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "57ea1c81-d9c5-489f-a126-df33d3f08e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster\n",
      "0     2336\n",
      "2     2055\n",
      "6     1948\n",
      "8     1628\n",
      "10    1543\n",
      "3     1423\n",
      "1     1334\n",
      "9      990\n",
      "7      979\n",
      "5      849\n",
      "4      446\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 11  # Adjust based on your dataset\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "\n",
    "# Fit K-Means to sentence-level embeddings\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# Assign clusters\n",
    "df_train_label[\"cluster\"] = kmeans.labels_\n",
    "df_test_label[\"cluster\"] = kmeans.predict(X_test)\n",
    "\n",
    "print(df_train_label[\"cluster\"].value_counts())  # Check cluster distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6212ea4-e71c-4b5f-8030-2ae45f131728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by cluster and topic_id to see distribution\n",
    "cluster_topic_distribution = df_train_label.groupby(['cluster', 'topic_id']).size().reset_index(name='count')\n",
    "\n",
    "# Find the most common topic_id in each cluster\n",
    "cluster_to_topic = cluster_topic_distribution.sort_values('count', ascending=False).drop_duplicates('cluster')\n",
    "\n",
    "# Create a mapping from cluster to topic_id\n",
    "cluster_topic_mapping = dict(zip(cluster_to_topic['cluster'], cluster_to_topic['topic_id']))\n",
    "\n",
    "# Assign the matched topic_id back to the DataFrame\n",
    "df_train_label['matched_topic_id'] = df_train_label['cluster'].map(cluster_topic_mapping)\n",
    "df_test_label['matched_topic_id'] = df_test_label['cluster'].map(cluster_topic_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50f225f4-4096-4e98-82eb-a212ce172e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.2832399716695641\n",
      "test accuracy: 0.2719546742209632\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = np.sum(df_train_label['matched_topic_id'] == df_train_label['topic_id'])/len(df_train_label)\n",
    "test_accuracy = np.sum(df_test_label['matched_topic_id'] == df_test_label['topic_id'])/len(df_test_label)\n",
    "print('train accuracy:', train_accuracy)\n",
    "print('test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db076ee7-05c9-4fb9-a6b1-248c17c64dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
