{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('df_train_sbert.csv')\n",
    "df_test = pd.read_csv('df_test_sbert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ec4edb9b8c489fa51b5eb05dff8446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/88911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc798eeb4174c2299757948db9623f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22228 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16671' max='16671' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16671/16671 47:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.206800</td>\n",
       "      <td>0.142347</td>\n",
       "      <td>0.943675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.129338</td>\n",
       "      <td>0.948039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>0.146082</td>\n",
       "      <td>0.949793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT Binary Classification Evaluation Results: {'eval_loss': 0.146081805229187, 'eval_accuracy': 0.9497930538060104, 'eval_runtime': 57.6213, 'eval_samples_per_second': 385.76, 'eval_steps_per_second': 12.062, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ---- Step 1: Load Pretrained SBERT ----\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"  # SBERT variant\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# ---- Step 2: Prepare the Data for Hugging Face Trainer ----\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer([str(text) for text in examples[\"processed_text\"]], \n",
    "                     padding=\"max_length\", \n",
    "                     truncation=True, \n",
    "                     max_length=128)\n",
    "\n",
    "\n",
    "# Convert Pandas DataFrame to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "test_dataset = Dataset.from_pandas(df_test)\n",
    "\n",
    "# Apply tokenization\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Set the format for PyTorch\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# ---- Step 3: Load SBERT with a Classification Head ----\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Binary classification\n",
    "\n",
    "# ---- Step 4: Training Arguments ----\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_binary_sbert\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs_binary_sbert\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "# ---- Step 5: Define Evaluation Metrics ----\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "# ---- Step 6: Initialize Trainer and Fine-Tune SBERT ----\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()  # ðŸš€ Fine-Tuning SBERT for Binary Classification\n",
    "\n",
    "# ---- Step 7: Evaluate SBERT Binary Model ----\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"SBERT Binary Classification Evaluation Results:\", eval_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**overfitting here, should consider the optimization hyperparam.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97     18301\n",
      "           1       0.83      0.90      0.86      3927\n",
      "\n",
      "    accuracy                           0.95     22228\n",
      "   macro avg       0.90      0.93      0.92     22228\n",
      "weighted avg       0.95      0.95      0.95     22228\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17582   719]\n",
      " [  397  3530]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Assume predictions_output is the result from trainer.predict(test_dataset)\n",
    "# For models that output logits, use argmax to convert to predicted labels.\n",
    "predictions_output = trainer.predict(test_dataset)\n",
    "predicted_labels = np.argmax(predictions_output.predictions, axis=1)\n",
    "true_labels = predictions_output.label_ids\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples predicted as in-topic: 16523\n",
      "Downstream training set shape: (16523, 14)\n",
      "Value counts for downstream topics:\n",
      "downstream_topic\n",
      "602.0    2646\n",
      "543.0    2331\n",
      "546.0    2261\n",
      "544.0    2149\n",
      "550.0    2085\n",
      "0.0      1818\n",
      "547.0    1498\n",
      "600.0     875\n",
      "554.0     367\n",
      "556.0     255\n",
      "552.0     238\n",
      "Name: count, dtype: int64\n",
      "Unique downstream topics mapping: {0.0: 0, 543.0: 1, 544.0: 2, 546.0: 3, 547.0: 4, 550.0: 5, 552.0: 6, 554.0: 7, 556.0: 8, 600.0: 9, 602.0: 10}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples predicted as in-topic: 4249\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- Step 1: Extract Predicted Positives from Binary Classifier ----\n",
    "X_train_bin = df_train[\"sbert_embedding\"]\n",
    "y_train_bin = df_train[\"label\"]\n",
    "# - binary_predict is defined from the upstream task\n",
    "\n",
    "# Get binary predictions on the training set\n",
    "# from the upstream task\n",
    "binary_preds_output = trainer.predict(train_dataset)\n",
    "binary_preds_train = np.argmax(binary_preds_output.predictions, axis=1) # array of 0s and 1s\n",
    "\n",
    "# Find indices where the binary classifier predicts positive (in-topic)\n",
    "positive_indices = np.where(binary_preds_train == 1)[0]\n",
    "\n",
    "print(\"Number of samples predicted as in-topic:\", len(positive_indices))\n",
    "\n",
    "# ---- Step 2: Build a New Training Set for the Downstream Classifier ----\n",
    "# We'll extract rows from df_train corresponding to predicted positives.\n",
    "# Then, for each extracted sample:\n",
    "#   - If the true binary label is 1 (i.e., it is a true positive), keep its original 'topic_id'\n",
    "#   - If the true binary label is 0 (i.e., a false positive), set its 'topic_id' to \"NP\"\n",
    "\n",
    "df_downstream = df_train.iloc[positive_indices].copy()\n",
    "\n",
    "# Create a new column for the downstream topic label:\n",
    "df_downstream['downstream_topic'] = df_downstream.apply(\n",
    "    lambda row: row['topic_id'] if row['label'] == 1 else 0.0, axis=1\n",
    ")\n",
    "\n",
    "# Now, df_downstream contains only the samples predicted as in-topic.\n",
    "# Their 'downstream_topic' column holds the original topic for true positives,\n",
    "# and \"NP\" for false positives.\n",
    "\n",
    "print(\"Downstream training set shape:\", df_downstream.shape)\n",
    "print(\"Value counts for downstream topics:\")\n",
    "print(df_downstream['downstream_topic'].value_counts())\n",
    "\n",
    "# ---- Step 3: (Optional) Prepare Data for Downstream BERT Fine-Tuning ----\n",
    "# For instance, if you want to fine-tune a BERT classifier on this subset:\n",
    "# Make sure your downstream training set contains:\n",
    "# - 'processed_text': the input text.\n",
    "# - 'downstream_topic': the new multiclass labels (including \"NP\").\n",
    "\n",
    "# You might need to remap 'downstream_topic' to contiguous integers, for example:\n",
    "unique_topics = np.sort(df_downstream['downstream_topic'].unique())\n",
    "topic_mapping = {topic: idx for idx, topic in enumerate(unique_topics)}\n",
    "df_downstream['mapped_topic'] = df_downstream['downstream_topic'].map(topic_mapping)\n",
    "\n",
    "print(\"Unique downstream topics mapping:\", topic_mapping)\n",
    "\n",
    "# At this point, you can use df_downstream to train your downstream classifier.\n",
    "# For example, you could convert it to a Hugging Face Dataset and fine-tune a BERT model:\n",
    "from datasets import Dataset\n",
    "downstream_dataset = Dataset.from_pandas(df_downstream)\n",
    "\n",
    "# Get binary predictions on df_test using your binary model Trainer (assumed already trained).\n",
    "# This returns an object; we extract predictions and then take argmax to get 0/1.\n",
    "binary_predictions_output = trainer.predict(test_dataset)  # 'trainer' is your binary model Trainer\n",
    "binary_preds_test = np.argmax(binary_predictions_output.predictions, axis=1)\n",
    "\n",
    "# Find indices where the binary classifier predicts in-topic (1)\n",
    "positive_indices_test = np.where(binary_preds_test == 1)[0]\n",
    "print(\"Number of test samples predicted as in-topic:\", len(positive_indices_test))\n",
    "\n",
    "# Create downstream test DataFrame from df_test (for multiclass stage).\n",
    "df_downstream_test = df_test.iloc[positive_indices_test].copy()\n",
    "\n",
    "# Create a new column 'downstream_topic':\n",
    "# If the true binary label is 1, use the true 'topic_id'; otherwise, mark as \"NP\".\n",
    "df_downstream_test['downstream_topic'] = df_downstream_test.apply(\n",
    "    lambda row: row['topic_id'] if row['label'] == 1 else 0.0, axis=1\n",
    ")\n",
    "\n",
    "# Map the downstream_topic to contiguous integers using topic_mapping.\n",
    "# (Ensure that topic_mapping is defined; for example, you might have built it from df_downstream.)\n",
    "df_downstream_test['mapped_topic'] = df_downstream_test['downstream_topic'].map(topic_mapping)\n",
    "\n",
    "# Create a Hugging Face Dataset for the downstream test set.\n",
    "downstream_dataset_test = Dataset.from_pandas(df_downstream_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37714d5638a41e4b75382fea4985555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16523 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1610f631d1ed4e028e89f004447934ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4249 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3099' max='3099' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3099/3099 08:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.810100</td>\n",
       "      <td>0.888143</td>\n",
       "      <td>0.728877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.774424</td>\n",
       "      <td>0.747705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.618600</td>\n",
       "      <td>0.765631</td>\n",
       "      <td>0.749823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT Multiclass Classification Evaluation Results: {'eval_loss': 0.7656312584877014, 'eval_accuracy': 0.749823487879501, 'eval_runtime': 9.9046, 'eval_samples_per_second': 428.991, 'eval_steps_per_second': 13.428, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# ---- Step 1: Convert Multiclass Data to Hugging Face Dataset ----\n",
    "downstream_dataset = Dataset.from_pandas(df_downstream)\n",
    "downstream_test_dataset = Dataset.from_pandas(df_downstream_test)\n",
    "\n",
    "# Apply tokenization\n",
    "downstream_dataset = downstream_dataset.map(preprocess_function, batched=True)\n",
    "downstream_test_dataset = downstream_test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Set the format for PyTorch\n",
    "downstream_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"mapped_topic\"])\n",
    "downstream_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"mapped_topic\"])\n",
    "\n",
    "# Rename mapped_topic to \"labels\" for Hugging Face Trainer compatibility\n",
    "downstream_dataset = downstream_dataset.rename_column(\"mapped_topic\", \"labels\")\n",
    "downstream_test_dataset = downstream_test_dataset.rename_column(\"mapped_topic\", \"labels\")\n",
    "\n",
    "# ---- Step 2: Load SBERT with Classification Head ----\n",
    "num_classes = len(np.unique(df_downstream[\"mapped_topic\"].values))  # Number of unique topics\n",
    "model_downstream = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
    "\n",
    "# ---- Step 3: Training Arguments for Multiclass ----\n",
    "training_args_multi = TrainingArguments(\n",
    "    output_dir=\"./results_multiclass_sbert\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs_multiclass_sbert\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "# ---- Step 4: Initialize Trainer and Fine-Tune SBERT for Multiclass ----\n",
    "trainer_multi = Trainer(\n",
    "    model=model_downstream,\n",
    "    args=training_args_multi,\n",
    "    train_dataset=downstream_dataset,\n",
    "    eval_dataset=downstream_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_multi.train()  # ðŸš€ Fine-Tuning SBERT for Multiclass Classification\n",
    "\n",
    "# ---- Step 5: Evaluate SBERT Multiclass Model ----\n",
    "eval_results_multi = trainer_multi.evaluate()\n",
    "print(\"SBERT Multiclass Classification Evaluation Results:\", eval_results_multi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does not seem to converge, also need to tune the optimization param.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downstream Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.04      0.08       719\n",
      "           1       0.75      0.93      0.83       555\n",
      "           2       0.66      0.56      0.61       489\n",
      "           3       0.76      0.94      0.84       529\n",
      "           4       0.89      0.96      0.92       400\n",
      "           5       0.68      0.92      0.78       515\n",
      "           6       0.75      0.79      0.77        53\n",
      "           7       0.72      0.92      0.81        76\n",
      "           8       0.81      1.00      0.89        46\n",
      "           9       0.86      0.98      0.92       213\n",
      "          10       0.75      0.98      0.85       654\n",
      "\n",
      "    accuracy                           0.75      4249\n",
      "   macro avg       0.74      0.82      0.76      4249\n",
      "weighted avg       0.71      0.75      0.69      4249\n",
      "\n",
      "Downstream Confusion Matrix:\n",
      "[[ 32  67 103 118  32 127  10  22   8  30 170]\n",
      " [  8 515   8   1   4   2   0   0   0   1  16]\n",
      " [ 15  90 274  22   7  70   0   1   1   0   9]\n",
      " [  1   3   7 498   0   9   0   0   2   0   9]\n",
      " [  2   1   6   2 383   3   0   0   0   1   2]\n",
      " [  6   5  13  11   2 474   2   0   0   1   1]\n",
      " [  0   0   1   2   0   7  42   0   0   1   0]\n",
      " [  1   0   0   0   0   0   0  70   0   0   5]\n",
      " [  0   0   0   0   0   0   0   0  46   0   0]\n",
      " [  0   2   1   0   0   1   0   0   0 209   0]\n",
      " [  2   1   0   1   1   0   2   4   0   0 643]]\n"
     ]
    }
   ],
   "source": [
    "predictions_output = trainer_multi.predict(downstream_test_dataset)\n",
    "predicted_labels = np.argmax(predictions_output.predictions, axis=1)\n",
    "true_labels = predictions_output.label_ids\n",
    "\n",
    "print(\"Downstream Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "print(\"Downstream Confusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to underperform BERT?? Maybe should choose different embedding for different task?? But BERT's outperformance is marginal, and SBERT is way faster. And it seems that SBERT suffer more from the direct choice of optimization param, so maybe tuning it a bit and it will work better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Œ Possible Improvements for Model Training\n",
    "\n",
    "## ðŸ”¹ 1. Binary Classification Model (Upstream)\n",
    "\n",
    "The binary classifier achieves **95% accuracy**, but signs of **overfitting** appear in the final epoch. The focus should be on improving **generalization** and **stability**.\n",
    "\n",
    "### âœ… Suggested Improvements:\n",
    "- **Early Stopping**  \n",
    "  - Stop training when validation loss stops improving to prevent overfitting.  \n",
    "  - Can be implemented using `EarlyStoppingCallback`.  \n",
    "\n",
    "- **Lower Learning Rate in Later Epochs**  \n",
    "  - Reduce the learning rate **after epoch 2** to slow down overfitting.  \n",
    "  - A scheduler like `get_scheduler(\"linear\")` can be used.  \n",
    "\n",
    "- **Regularization (Dropout & Weight Decay)**  \n",
    "  - Add **dropout (0.1-0.3)** to the classifier head.  \n",
    "  - Apply **L2 weight decay** (`weight_decay=0.01`).  \n",
    "\n",
    "- **Adjust Decision Threshold for Upstream Classification**  \n",
    "  - Instead of the default **0.5 threshold**, increase it to **0.6 or 0.7** to reduce false positives.  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ 2. Multi-Class Classification Model (Downstream)\n",
    "\n",
    "The multi-class classifier reaches **75% accuracy**, but validation loss **stabilizes early**, suggesting that improvements can be made in **training strategy, data filtering, and model complexity**.\n",
    "\n",
    "### âœ… Suggested Improvements:\n",
    "- **Extend Training with Lower Learning Rate**  \n",
    "  - Since validation loss is still decreasing, increase training to **5 epochs** while lowering the learning rate.  \n",
    "\n",
    "- **Class-Balanced Loss Function**  \n",
    "  - Some classes are underrepresented, leading to imbalance.  \n",
    "  - Use **weighted cross-entropy loss** to address this.  \n",
    "\n",
    "- **Filter Low-Confidence Samples from Upstream Model**  \n",
    "  - Some false positives from the binary classifier introduce noise.  \n",
    "  - Remove samples with low upstream confidence scores (**probability < 0.7**).  \n",
    "\n",
    "- **Data Augmentation for Rare Classes**  \n",
    "  - Use **paraphrasing techniques** (e.g., `nlpaug`) to generate more examples for underrepresented topics.  \n",
    "\n",
    "- **Increase Model Complexity**  \n",
    "  - Instead of using a single-layer MLP, explore **multi-layer MLPs or attention-based classifiers** for better generalization.  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "- âœ… Implement **early stopping & regularization** for the binary model.  \n",
    "- âœ… Introduce **confidence-based filtering & class weighting** for the multi-class model.  \n",
    "- âœ… Experiment with **extended training & alternative classifiers**.  \n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
